{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "https://www.hackdeploy.com/tensorflow-word2vec-tutorial-from-scratch/",
   "metadata": {
    "tags": [],
    "cell_id": "00000-49f7740c-96de-4320-98f6-690d194f633f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Skip-Gram Model \n#### Predicting context words given center word",
   "metadata": {
    "tags": [],
    "cell_id": "00000-3f1d46dd-353a-4ce0-8096-7b351842ee86",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-12c62e91-b344-4b70-90bb-64be2426a956",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "77fa86aa",
    "execution_start": 1620769656996,
    "execution_millis": 3529,
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\nfrom collections import Counter\nfrom collections import defaultdict\nimport tensorflow as tf\n# import unittest",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "A bag-of-words is a representation of text that describes the occurrence of words within a document. It is called a “bag” of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.",
   "metadata": {
    "tags": [],
    "cell_id": "00002-191655fc-dc76-4de7-967d-cd191d872abc",
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-1110c387-c97f-45bf-ab38-dadeca6a84b1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7a5ce973",
    "execution_start": 1620769660527,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "# Dataset we are using\n\n\nSENTENCES = [\n             \"machine learning engineers can build great data models\",\n             \"the more data you have the better your model\",\n             \"these predictions sound right, but it is all about your data\",\n             \"your data can provide great value\"\n            ]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00003-daf790be-2ce1-4b9f-8a2b-5f6e8fce70b2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ec0c8ac5",
    "execution_start": 1620769660537,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "# Bag of words function\n\ndef bag_of_words(input_sentence:list, delimiter=\" \") -> dict:\n    '''Converts the input_sentence to bag of words representation\n\n    Parameters\n    ----------\n    input_sentence : iterable\n        Text to be converted to bag of words\n    delimiter : char\n        Words in the text are separated by this character\n    \n    Returns\n    -------\n    output : dict\n        Dictionary of words and their frequency\n    '''\n    output = Counter()\n    # print(input_sentence[0].split(delimiter))\n    for sentence in input_sentence:\n            output.update(sentence.split(delimiter))\n\n    return dict(output)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-7101921e-7abb-4e68-be4b-db992977f1ec",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7a4b7c9e",
    "execution_start": 1620769660544,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "# Unit Test\ndef test_bag_of_words():\n    sentences = [\"Deep learning is a Deep concept\"]\n    expected_output = {'Deep': 2, 'learning':1, 'is': 1, 'a': 1, 'concept': 1}\n    received_output = bag_of_words(sentences)\n    assert expected_output == received_output, f\"\\n Expected Output= {expected_output}\\\n                                             vs \\n Returned Output= {received_output} \\n\"\n    \ntest_bag_of_words()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-7b264047-de97-4a89-8159-c0bf1f1a3f8b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1ffdd4f1",
    "execution_start": 1620769660551,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "source": "def generate_vocabulary():\n    pass\n\ndef get_word_to_index(bag_of_words : dict):\n    ''' Returns a mapping from word to its index in the vocab\n\n    Parameters\n    ----------\n    bag_of_words : dict\n        A frequency dictionary of words appearing in text\n\n    Returns\n    -------\n    word_to_idx : dict\n        A dictionary map from word to its index\n    '''\n    word_to_idx = {word:index  for index,word in enumerate(bag_of_words.keys())}\n    return word_to_idx\n\ndef get_index_to_word(bag_of_words : dict):\n    ''' Returns a mapping from index to corresponding word in the vocab\n\n    Parameters\n    ----------\n    bag_of_words : dict\n        A frequency dictionary of words appearing in text\n\n    Returns\n    -------\n    idx_to_word : dict\n        A dictionary map from index to corresponding word\n    '''\n    idx_to_word = {index:word  for index,word in enumerate(bag_of_words.keys())}\n    return idx_to_word",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-a22cfed1-10d2-4f77-b8cf-b3261bde931e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d5f9c812",
    "execution_start": 1620769660560,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "word_to_index = get_word_to_index(bag_of_words(SENTENCES))\nindex_to_word = get_index_to_word(bag_of_words(SENTENCES))\nprint(word_to_index,index_to_word)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "{'machine': 0, 'learning': 1, 'engineers': 2, 'can': 3, 'build': 4, 'great': 5, 'data': 6, 'models': 7, 'the': 8, 'more': 9, 'you': 10, 'have': 11, 'better': 12, 'your': 13, 'model': 14, 'these': 15, 'predictions': 16, 'sound': 17, 'right,': 18, 'but': 19, 'it': 20, 'is': 21, 'all': 22, 'about': 23, 'provide': 24, 'value': 25} {0: 'machine', 1: 'learning', 2: 'engineers', 3: 'can', 4: 'build', 5: 'great', 6: 'data', 7: 'models', 8: 'the', 9: 'more', 10: 'you', 11: 'have', 12: 'better', 13: 'your', 14: 'model', 15: 'these', 16: 'predictions', 17: 'sound', 18: 'right,', 19: 'but', 20: 'it', 21: 'is', 22: 'all', 23: 'about', 24: 'provide', 25: 'value'}\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-650f3416-3acc-467e-af3a-f58ff7bab53f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "311bfd41",
    "execution_start": 1620769672453,
    "execution_millis": 10,
    "deepnote_cell_type": "code"
   },
   "source": "def generate_skip_gram_training_data(text_corpus,window_size):\n    # Assuming text corpus as a list of strings.\n    training_data = defaultdict(set)\n    x = []\n    y = []\n    for sentence in text_corpus:\n        words = sentence.split(\" \")\n        \n        for i in range(len(words)):\n            from_index = max(i-window_size,0)\n            to_index = min(i+1+window_size,len(words))\n            training_data[words[i]].update(set(words[from_index:to_index]))\n            training_data[words[i]].remove(words[i])\n\n    for center_word,context in training_data.items():\n        for word in context:\n            #train_data.append((center_word,word))\n            x.append(center_word)\n            y.append(word)\n\n    words_dict = get_word_to_index(bag_of_words(text_corpus))\n    x_indices = [words_dict[k] for k in x]\n    y_indices = [words_dict[k] for k in y]\n    x_indices = tf.convert_to_tensor(x_indices)\n    y_indices = tf.convert_to_tensor(y_indices)\n    x_indices = tf.keras.utils.to_categorical(x_indices)\n    y_indices = tf.keras.utils.to_categorical(y_indices)\n    train_data = tf.data.Dataset.from_tensor_slices((x_indices,y_indices))\n    return train_data",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-58fc1a3b-c08c-4d16-97aa-1f5e970c3f38",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d7cb0cae",
    "execution_start": 1620769673347,
    "execution_millis": 46,
    "deepnote_cell_type": "code"
   },
   "source": "train_data = generate_skip_gram_training_data(SENTENCES,3)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-be54bbf8-6c86-434f-bdb2-aeb94e64642a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d2c65c14",
    "execution_start": 1620770066043,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "for element in train_data.as_numpy_iterator():\n    print(index_to_word[np.argmax(element[0])])\n    print(index_to_word[np.argmax(element[1])])\n    print(f\"len of vocabulary is {len(element[0])}\")\n    break",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "machine\ncan\nlen of vocabulary is 26\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00012-a2082033-fb25-4c04-a142-7a68508c9388",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-f6652899-6938-4bc3-8331-66cd73d10e23",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bacd64b",
    "execution_start": 1620770453318,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "def define_model():\n\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Dense(64,activation=tf.nn.relu,input_shape=(26,)))\n    model.add(tf.keras.layers.Dense(10,activation=tf.nn.relu)) # We will get embeddings of 10 dimesnsions\n    model.add(tf.keras.layers.Dense(26,activation=tf.nn.softmax))\n\n    return model",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00014-60c883b1-0952-421e-901e-1215bccb7459",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8a7f838f",
    "execution_start": 1620770479306,
    "execution_millis": 18,
    "deepnote_cell_type": "code"
   },
   "source": "model = define_model()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00015-86c49d23-7849-4364-b32f-2362aa89326b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6134d8ef",
    "execution_start": 1620770517023,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00016-aedfd5e9-242e-43e5-b1a4-fcd47c6cd094",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cc989ed0",
    "execution_start": 1620770882453,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "test_dataset = train_data.take(34) \ntrain_dataset = train_data.skip(34)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00017-f3b03f37-de1a-485a-8c02-0e8daec26421",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "800d09fd",
    "execution_start": 1620771099575,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "test_dataset = test_dataset.batch(5)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00017-0ee09e76-ddf3-4b4a-8904-026272ad7645",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9b35cd72",
    "execution_start": 1620770906377,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "train_dataset = train_dataset.batch(5)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00016-e559d7a0-1553-40ce-9ac7-94f56837e58a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4602496e",
    "execution_start": 1620771030693,
    "execution_millis": 3048,
    "deepnote_cell_type": "code"
   },
   "source": "model.fit(train_dataset,epochs=100)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0364\nEpoch 2/100\n22/22 [==============================] - 0s 994us/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 3/100\n22/22 [==============================] - 0s 954us/step - loss: 1.7869 - accuracy: 0.0364\nEpoch 4/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 5/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0364\nEpoch 6/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0818\nEpoch 7/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0364\nEpoch 8/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0818\nEpoch 9/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 10/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 11/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 12/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0818\nEpoch 13/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 14/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.1182\nEpoch 15/100\n22/22 [==============================] - 0s 998us/step - loss: 1.7871 - accuracy: 0.0455\nEpoch 16/100\n22/22 [==============================] - 0s 985us/step - loss: 1.7871 - accuracy: 0.1091\nEpoch 17/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7872 - accuracy: 0.0545\nEpoch 18/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7871 - accuracy: 0.1091\nEpoch 19/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7872 - accuracy: 0.0545\nEpoch 20/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7871 - accuracy: 0.0818\nEpoch 21/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7871 - accuracy: 0.0727\nEpoch 22/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0636\nEpoch 23/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0727\nEpoch 24/100\n22/22 [==============================] - 0s 990us/step - loss: 1.7868 - accuracy: 0.0364\nEpoch 25/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0727\nEpoch 26/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0364\nEpoch 27/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7868 - accuracy: 0.0727\nEpoch 28/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0364\nEpoch 29/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 30/100\n22/22 [==============================] - 0s 953us/step - loss: 1.7868 - accuracy: 0.0364\nEpoch 31/100\n22/22 [==============================] - 0s 1000us/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 32/100\n22/22 [==============================] - 0s 986us/step - loss: 1.7868 - accuracy: 0.0455\nEpoch 33/100\n22/22 [==============================] - 0s 975us/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 34/100\n22/22 [==============================] - 0s 983us/step - loss: 1.7868 - accuracy: 0.0455\nEpoch 35/100\n22/22 [==============================] - 0s 985us/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 36/100\n22/22 [==============================] - 0s 984us/step - loss: 1.7868 - accuracy: 0.0636\nEpoch 37/100\n22/22 [==============================] - 0s 1000us/step - loss: 1.7868 - accuracy: 0.0909\nEpoch 38/100\n22/22 [==============================] - 0s 999us/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 39/100\n22/22 [==============================] - 0s 994us/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 40/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 41/100\n22/22 [==============================] - 0s 996us/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 42/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 43/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 44/100\n22/22 [==============================] - 0s 983us/step - loss: 1.7870 - accuracy: 0.0545\nEpoch 45/100\n22/22 [==============================] - 0s 982us/step - loss: 1.7869 - accuracy: 0.0727\nEpoch 46/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 47/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0545\nEpoch 48/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 49/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0545\nEpoch 50/100\n22/22 [==============================] - 0s 997us/step - loss: 1.7868 - accuracy: 0.0455\nEpoch 51/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0364\nEpoch 52/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0545\nEpoch 53/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 54/100\n22/22 [==============================] - 0s 999us/step - loss: 1.7867 - accuracy: 0.0636\nEpoch 55/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 56/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0727\nEpoch 57/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0455\nEpoch 58/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0636\nEpoch 59/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 60/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0818\nEpoch 61/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 62/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0818\nEpoch 63/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0364\nEpoch 64/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 65/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0455\nEpoch 66/100\n22/22 [==============================] - 0s 980us/step - loss: 1.7868 - accuracy: 0.0818\nEpoch 67/100\n22/22 [==============================] - 0s 986us/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 68/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0909\nEpoch 69/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 70/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7868 - accuracy: 0.0909\nEpoch 71/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 72/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0909\nEpoch 73/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0545\nEpoch 74/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.1091\nEpoch 75/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0545\nEpoch 76/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7868 - accuracy: 0.1091\nEpoch 77/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7869 - accuracy: 0.0455\nEpoch 78/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7868 - accuracy: 0.0727\nEpoch 79/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7868 - accuracy: 0.0545\nEpoch 80/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7867 - accuracy: 0.0455\nEpoch 81/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0636\nEpoch 82/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 83/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0636\nEpoch 84/100\n22/22 [==============================] - 0s 987us/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 85/100\n22/22 [==============================] - 0s 999us/step - loss: 1.7867 - accuracy: 0.0727\nEpoch 86/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.0455\nEpoch 87/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.0636\nEpoch 88/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.0455\nEpoch 89/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0545\nEpoch 90/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 91/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.0727\nEpoch 92/100\n22/22 [==============================] - 0s 2ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 93/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.0636\nEpoch 94/100\n22/22 [==============================] - 0s 981us/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 95/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.0818\nEpoch 96/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0364\nEpoch 97/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.0818\nEpoch 98/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0455\nEpoch 99/100\n22/22 [==============================] - 0s 995us/step - loss: 1.7867 - accuracy: 0.0818\nEpoch 100/100\n22/22 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.0455\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 40,
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f82d048df90>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00017-fbbc42ce-30b5-4a0d-9657-d241b5f31d52",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "55c64df5",
    "execution_start": 1620771104086,
    "execution_millis": 93,
    "deepnote_cell_type": "code"
   },
   "source": "model.evaluate(test_dataset)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "7/7 [==============================] - 0s 2ms/step - loss: 11.7989 - accuracy: 0.0000e+00\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 43,
     "data": {
      "text/plain": "[11.79892635345459, 0.0]"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00020-ccccf6fa-3bab-40ad-9966-7e6c710bb472",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5011a99c",
    "execution_start": 1620771259397,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "embedding = model.layers[1]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00022-598354a3-7a77-4eba-9365-d6f323f5688e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "74d5a055",
    "execution_start": 1620771979604,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "list(train_dataset.as_numpy_iterator())[0][0].shape",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 70,
     "data": {
      "text/plain": "(26,)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00022-0fcb7b22-375d-48eb-bf40-6d0e21980e05",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d7936c05",
    "execution_start": 1620771997595,
    "execution_millis": 41,
    "deepnote_cell_type": "code"
   },
   "source": "intermediate_layer_model = tf.keras.Model(inputs=model.input,\n                                       outputs=model.layers[1].output)\nintermediate_output = intermediate_layer_model(list(train_dataset.as_numpy_iterator())[0][0])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00023-bddf9c4f-0828-48b4-b1d0-f26bf65510b0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bec1426c",
    "execution_start": 1620772003690,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "intermediate_output",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 72,
     "data": {
      "text/plain": "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\narray([[4.434657  , 1.2535803 , 5.280507  , 0.        , 0.        ,\n        3.9689    , 0.        , 0.88672835, 6.474742  , 9.228638  ],\n       [4.434657  , 1.2535803 , 5.280507  , 0.        , 0.        ,\n        3.9689    , 0.        , 0.88672835, 6.474742  , 9.228638  ],\n       [4.434657  , 1.2535803 , 5.280507  , 0.        , 0.        ,\n        3.9689    , 0.        , 0.88672835, 6.474742  , 9.228638  ],\n       [4.434657  , 1.2535803 , 5.280507  , 0.        , 0.        ,\n        3.9689    , 0.        , 0.88672835, 6.474742  , 9.228638  ],\n       [4.434657  , 1.2535803 , 5.280507  , 0.        , 0.        ,\n        3.9689    , 0.        , 0.88672835, 6.474742  , 9.228638  ]],\n      dtype=float32)>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00025-d6dfc34f-592b-4c8a-8236-adb139c22454",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=dcd03e1a-e120-4eeb-b05f-6684779c3d8f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "8735f005-dec7-40f9-8ba7-4f6272cc9200",
  "deepnote_execution_queue": []
 }
}